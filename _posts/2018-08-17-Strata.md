---
layout: page
title: Strata -- A Cross Media File System
tags: [New Hardware, File System]
excerpt_separator: <!--more-->
typora-root-url: ../
---



## Strata: A Cross Media File System

### 0x00 引言

  这篇Paper是SOSP'17上面的一篇关于跨介质文件系统的文章。现在的持久化的存储介质有NVM、SSD和传统的HDD，它们有着各自不同的特点。而现在的很多文件系统都是针对其中一种存储介质进行优化，比如NOVA之于NVM、F2FS面向SSD已经ext4对HDD。这篇Paper则提出利用类似LSM-tree的方法，将文件系统系统做成层次化的结构，利用好不同介质的不同的特点。

```
... Strata using a 3-layer storage hierarchy of emulated NVM, a flash-based SSD, and a high-density HDD. Strata has 20-30% better latency and throughput, across several unmodified applications, compared to file systems purpose-built for each layer, while providing synchronous and unified access to the entire storage hierarchy. Finally, Strata achieves up to 2.8× better throughput than a block-based 2-layer cache provided by Linux’s logical volume manager.
```

Strata(Stratum，地层、阶层)中出现的一些概念，

![strata-concepts](/assets/img/strata-concepts.png)

### 0x01 基本设计

 Strata的基本结构如下图。Strata的几个设计要点：

* Strata的基本架构类似与LSM-tree。Strata的写入操作开始时使用logging的方式写入到NVM上面，Log的方式加上NVM的硬件特性，对小数据写入、一致性、Crash恢复以及操作原子性都有利。以这样的方式写入到NVM里面有利于写但是不利于查找和读操作。Strata在合适的时候将log“消化”到下一层的存储设备上，在这里的存储格式是为读取优化的。
* Log at user-level, digest in the kernel，NVM的高性能使用传统的syscall的方式会造成很大的overhead。Strata为了解决这个问题，使用了user-level的实现的方式。这个思路也和很多的user-level网络栈实现的思路一致。而digest操作则会在kernel中异步并行地进行。
* Sequential, aligned writes，digest的工作方式也是的写入到下一层级的存储介质上时数据的是大块的。而且可以在digest操作是进行垃圾回收，合并写操作以及降低碎片。
* Use hardware-assisted protection，Log在user-level完成，Strata借助硬件虚拟化的技术来保障子啊bypass-kernel的情况下的安全性；
* Strate的元数据和一般的文件系统没有什么差别，也是Superblock，Inodes，目录以及空闲空间管理的结构组成的。而且Strate可以将多个存储设备实例当作一个逻辑上的设备使用。

![strata-arch](/assets/img/strata-arch.png)

### 0x02 其它一些

#### LibFS

 LibFS的几点设计：

* 快速同步持久化操作，Strate使用直接写入到NVM的方式，不使用说明Page Cahe之类的，避免了这个带来的一些开销。通过简单的同步的持久化的语义，也使得应用的一些操作变得简单(想想在经常出现的fsync操作)。另外，Strate的log为一种operation log，降低了一些写入的数据的量。Strate还使得log是幂等的。
* Crash一致的logging，Strata使用Strata transaction的方式来保持操作的ACID的特性。另外，Strata的log中包含了足够的想象，而且log操作保障了操作应用的顺序，也使得保证文件系统一致性变得简单；
* Digest操作和GC，在log的量达到一个阈值的时候，会请求KernelFS进行digest操作。在这恶搞过程中就可以进行GC操作。
* 快读读取，LibFS会将一些数据和元数据Cache在内存中。Cache的数据只会来自SSD或者是HDD。



#### KernelFS

KernelFS的几点设计：

* Digest操作，KernelFS的Digest操作会将LibFS生成的operation log转化为每一个文件一个的extent tree。在这个过程中可以进行垃圾回收，合并写操作，减少碎片化等。由于Digest操作是大块的写入，而且在一定的情况下，写入的数据是可知的，这样给KernelFS将数据写入下一层级的时候比较大的优化的空间；

* Data access pattern interface，由于Strata是一种层级式的结构，所以KernelFS得维持多个的LRU的list用于数据迁移，这个list的数量根据层级的数量确定。这个是2，分别是NVM到SSD，SSD到HDD。另外一些访问的信息在LibFS中，所以也需要LibFS相关的配合，

  ```
   LibFS can submit access information as frequently as it wishes via a system call. KernelFS transforms the LibFS-provided LRU lists into coarser-grained lists for storage layers that have larger block sizes (e.g., 1MB blocks for NVM and 4MB for SSD).
  ```

* Data migration，数据迁移的做法类似于LSM-tree合并的操作，为了提高迁移的效率和减少碎片话，迁移到SSD的时候一次迁移数百MB的数据，迁移到HDD的时候为数GB的数据。



#### 局限

在目前的Strata的实现中存在的一些问题or局限：

* Kernel，LibFS 和 KernelFS目前通信的方式是通过Socket，这个在一些情况下可能造成比较大的overhead。但是Paper中又认为这个影响比较小；

* Leases，即Sharing (leases)，这个功能还没有完全实现，现在还存在一些问题，

  ```
   To guarantee strict ordering and synchronous persistence, LibFS must first acquire a lease in order to create the lock file and relinquish the lease and perform a digest after the lock file is unlinked. Strata achieves a throughput of 10,400 updates/s, 4.3× slower than EXT4-DAX and 1.7× slower than NOVA. 
  ```

* Memory mapped files，没有实现这个功能。目前要在Strata中实现存在一些问题，比如小数据的随机写入操作的写入放大的问题；

* Fault tolerance，目前还没有容忍存储设备故障的机制。



### 0x03 评估

具体的信息可以参看[1]，从下面的这个图看出来小文件的优化才是重点鸭🦆。

![strata-perf](/assets/img/strata-perf.png)



### 参考

1. Strata: A Cross Media File System, SOSP'17.