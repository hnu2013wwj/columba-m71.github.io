---
layout: page
title: MemC3
tags: [Data Structure, Key-Value]
excerpt_separator: <!--more-->
typora-root-url: ../
---



## MemC3: Compact and Concurrent MemCache with Dumber Caching and Smarter Hashing 



### 0x00 引言

​	这篇paper是关于优化memcached内部实现的。主要包含了几个方面，这里只关注**optimistic cuckoo hashing** 。

```
As a case study, we focus on Memcached [19], a popular in-memory caching layer, and show how our toolbox of techniques can improve Memcached’s perfor- mance by 3× and reduce its memory use by 30%.
```

   主要优化的是针对一下的场景，在论文[2]中有详细的讨论。场景主要的特点就是读占绝大部分，大部分的key-value都比较小。

```
Most keys are smaller than 32 bytes and most values no more than a few hundred bytes. In particular, there is one common type of request that almost exclusively uses 16 or 21 Byte keys and 2 Byte values.
```



### 0x01 Optimistic Cuckoo Hashing

 	Cuckoo Hash的基本思路是使用不止一个的hash函数来决定一个对象存放的位置，并使用驱逐的方法解决一些冲突的问题。这里的Hash Table的实现使用了类似Cache中组相联的方式，对于个位置，不只是放一个对象，而是一组的Slot。​

![memc3-cuckoo](/assets/img/memc3-cuckoo.png)

​	

  这里的实现使用 了4个slot，paper有这样一个说明，可以看出，使用这样的方式的一个好处就是可以提高空间的使用率。

```
Our hash table is 4-way set-associative. Without set-associativity, basic cuckoo hashing allows only 50% of the table entries to be occupied before unresolvable collisions occur. It is possible to improve the space utilization to over 90% by using a 4-way (or higher) set associative hash table. 
```

 此外，另外的一个好处就是更加缓存友好。

  一个slot没有直接包含key-value pairt，因为它们的程度不固定。这个slot有两部分组成，一个是信息来自key的一个tag，另外一个是指向完整key-value pair + 元数据的结构。由于这里使用了2个hash函数。所以每次最多查找的slot是8个。另外，对于insert的操作来说，如果bucket都满了，就会驱逐已经存在的元素。如果这个驱逐这个过程被级联的执行了太多次，就会执行hash table的操作。



##### Tag-based Lookup 

 之前提到了每一个slot有一个信息来集key的一个tag，这里的用处就是用了提高缓存友好性。tag实际上由key的hash得到，长度是1 byte。这样，对于不想等的key，就有很大的几率可以不同访问完整的key-value结构，而slot在这个时候已经被访问了，有很大的几率这些数据就在Cache中，这样就能提高性能。

```
After checking all 8 candidate slots, a negative Lookup makes 8 × 0.39% = 0.03 pointer deref- erences on average. Because each bucket fits in a CPU cacheline (usually 64-Byte), on average each Lookup makes only 2 parallel cacheline-sized reads for checking the two buckets plus either 0.03 pointer dereferences if the Lookup misses or 1.03 if it hits.
```



##### Tag-based Insert

 Tag 除了优化了查找之外，还可以优化insert操作。这个的核心在与这样的计算方法(这里实在是太巧妙了):

```
b1 = HASH(x) // based on the entire key
b2 = b1 ⊕ HASH(tag) //based on b1 and tag of x
```

  这样做的一个好处就是可以从b2 和 tag 得出 b1. 得知b1时也可以得到b2。这样的好处就是insert操作只需要table中的数据，而不同取回一些keys。

```
 more importantly b1 can be computed by the same formula from b2 and tag. This property ensures that to displace a key originally in bucket b—no matter if b is b1 or b2— it is possible to calculate its alternate bucket b′ from bucket index b and the tag stored in bucket b by 
 	b′ = b ⊕ HASH(tag)
```



### 0x03 Concurrent Cuckoo Hashing 

   对于并发的情况，这里主要要解决2个问题：

1. Deadlock risk (writer/writer)：产生的原因是insert操作会可能移动一些key，而具体的移动情况是未知的，就可能导致deadlock。

2. False misses (reader/writer)：在一个key被驱逐到另外一个bucket的时候，存在一段时间是无法被查找到的。

   

  对于第二个问题，将查找一条合法的cuckoo path和执行具体的操作分离开，当得到一条path的时候，从这个path的最后一个开始移动。这样就很好的解决了这个问题。这样的一个结果就是可能在一段时间内，一个key存在两条记录，不过这里这个没有太大的关系。

  对于第一个问题，则就是使用了一个简单的办法，同一时间只能由一个writer：

```
To avoid writer/writer deadlocks, it allows only one writer at a time — a tradeoff we accept as our target workloads are read-heavy.
```



##### Optimistic Locks for Lookup 

  查找的一个优化，就是使用了一种类型OCC(乐观并发控制)的方式，不lock一个bucket，而是给每一个key一个version counter，利用这个version来观测数据是否被修改了。这里利用了single writer的特点。

```
Optimizing for the common case, our approach takes advantage of having a single writer to synchronize Insert and Lookups with low overhead. Instead of locking on buckets, it assigns a version counter for each key, updates its version when displacing this key on Insert, and looks for a version change during Lookup to detect any concurrent displacement.
```



##### Multiple Cuckoo Paths 

  这个是对于一个inser操作的优化，在查找cuckoo path的阶段，不只是查找一条path，而是同时查找多条path。从其中选择一条最优的来决定最终的insert操作。



### 0x04 其它

 这里只关注了**optimistic cuckoo hashing**的部分，关于论文的其它部分可以参看原论文。此外，这篇论文有一个进一步优化的版本，之后加上。



## 参考

1. MemC3: Compact and Concurrent MemCache with Dumber Caching and Smarter Hashing，NSDI ’13.
2.  B. Atikoglu, Y. Xu, E. Frachtenberg, S. Jiang, and M. Paleczny. Workload analysis of a large-scale key-value store. In Proceedings of the SIGMETRICS’12, 2012. 